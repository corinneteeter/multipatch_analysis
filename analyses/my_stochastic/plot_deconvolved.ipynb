{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The binomial parameter analysis here is inspired by the following manuscripts:\n",
    "\n",
    "* Costa et al 2013. https://www.frontiersin.org/articles/10.3389/fncom.2013.00075/full\n",
    "* Malinow and Tsien 1990. https://www.nature.com/articles/346177a0\n",
    "* Tarczy-hornoch et al 1999. https://academic.oup.com/cercor/article/9/8/833/346715\n",
    "* Bremaud et al 2007. https://www.pnas.org/content/104/35/14134.long\n",
    "\n",
    "In the images below I have have looked at two synapse types, pv to pv, and tlx3 to sst (look for tlx3 to sst are at the bottom).  I have not made summary plots yet.  Each connection has four plots associated with it.  All plots are for deconvolved amplitudes.  It starts with a plot of the amplitudes of the entire experiment.  Then I plot the 50 Htz trains, the mean vs coefficient of variation for each pulse of the 50 htz trains, and histograms of the amplitudes of first pulses from every train (not just 50 htz).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "font={'size':14}\n",
    "matplotlib.rc('font', **font)\n",
    "#need to add in qc and mean\n",
    "# still need to add pre synaptic spike number qc. ie.e does more than one presynaptic spike happen?\n",
    "# what if a postsynaptic pulse happens and it does not pass qc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_csv(filename):\n",
    "    \"\"\"Get data from a specified csv file.  Note the data arrays were written as strings with \n",
    "    funky things in them by pandas.to_csv.  Here they are pulled out and put in a dictionary as\n",
    "    numpy arrays.\n",
    "    Input\n",
    "    -----\n",
    "    filename: string\n",
    "        file name or path to file\n",
    "    Returns\n",
    "    -------\n",
    "    d: dictionary\n",
    "        contains data for connections\n",
    "        \"\"\"\n",
    "    \n",
    "    data = pd.read_csv(filename)\n",
    "    d={}\n",
    "    d['amps'] = []\n",
    "    d['spike_times_relative_to_expt'] = []\n",
    "    d['post_syn_rec_id'] = []\n",
    "    d['expt_start_time'] = []\n",
    "    d['post_id'] = data['post_id']\n",
    "    d['pre_id'] = data['pre_id']\n",
    "    d['post_cre'] = data['post_cre']\n",
    "    d['pre_cre'] = data['pre_cre']\n",
    "    d['uid'] = data['uid']\n",
    "    d['stim_freq'] = []\n",
    "    d['pulse_num_within_train'] = []\n",
    "#    d['qc_mask'] = []\n",
    "    \n",
    "    #convert weird string from cvs to arrays\n",
    "    for ii in range(len(data)):\n",
    "        d['amps'].append(np.fromstring(data['deconvolved_amps'][ii].replace('\\n', '').replace('[', '').replace(']', ''), dtype=float, sep=' '))\n",
    "        d['spike_times_relative_to_expt'].append(np.fromstring(data['spike_times_relative_to_experiment'][ii].replace('\\n', '').replace('[', '').replace(']', ''), dtype=float, sep=' '))\n",
    "        d['expt_start_time'].append(d['spike_times_relative_to_expt'][-1][0])\n",
    "        d['post_syn_rec_id'].append(np.fromstring(data['post_syn_rec_id'][ii].replace('\\n', '').replace('[', '').replace(']', ''), dtype=int, sep=' '))\n",
    "        d['pulse_num_within_train'].append(np.fromstring(data['pulse_num_within_train'][ii].replace('\\n', '').replace('[', '').replace(']', ''), dtype=int, sep=' '))\n",
    "        #print(data['stim_freq'][ii])\n",
    "        d['stim_freq'].append(np.fromstring(data['stim_freq'][ii].replace('\\n', '').replace('[', '').replace(']', ''), dtype=float, sep=' '))\n",
    "        if (len(d['amps'][-1]) != len(d['spike_times_relative_to_expt'][-1])) or \\\n",
    "            (len(d['amps'][-1]) != len(d['post_syn_rec_id'][-1])) or \\\n",
    "            (len(d['amps'][-1]) != len(d['stim_freq'][-1])) or \\\n",
    "            (len(d['amps'][-1]) != len(d['pulse_num_within_train'][-1])):\n",
    "            raise Exception('string to array conversion probably went wrong')\n",
    "    return d\n",
    "\n",
    "filename='pv_tlx_to_sst.csv'\n",
    "data=get_data_from_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_std_of_amps_in_df(df):\n",
    "    \"\"\"standard deviation of each pulse in train.  Doing\n",
    "    this calculation by had here because df['amps'].std() is not working.\"\"\"\n",
    "    stuff=[]\n",
    "    for ii, row in df.iterrows(): #/fifty['times_rel_to_train'].mean() \n",
    "        stuff.append(row['amps'])\n",
    "    var=np.array(stuff).var(axis=0)\n",
    "    std=np.array(stuff).std(axis=0)\n",
    "    return var, std  \n",
    "\n",
    "def remove_neg_coupled_data(a,b):\n",
    "    \"\"\"\n",
    "    Remove negative data from arrays.  If a number is negative in a it's pair is removed\n",
    "    from b and visa versa.\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    a : numpy array\n",
    "    b : numpy array\n",
    "    \n",
    "    a and b should have the same length\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    a2 : numpy array\n",
    "    b2 : numpy array\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if len(a) != len(b):\n",
    "        raise Exception('input arrays should be the same length')\n",
    "    a1 = np.extract(a>0, a) #remove negative a data from a\n",
    "    b1 = np.extract(a>0, b) #remove negative a data indexs from b\n",
    "    \n",
    "    a2 = np.extract(b1>0, a1) #remove negative b data index from a\n",
    "    b2 = np.extract(b1>0, b1) #remove negative b data from b\n",
    "    \n",
    "    if len(a2) != len(b2):\n",
    "        raise Exception('output arrays should be the same length')\n",
    "    \n",
    "    return a2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Grab 50 Htz data and make plots if desired\n",
    "\n",
    "show_plot= False\n",
    "summary_50htz={}\n",
    "summary_50htz['mean'] = []\n",
    "summary_50htz['cv'] = []\n",
    "summary_50htz['uid'] = []\n",
    "summary_50htz['pre_id'] = []\n",
    "summary_50htz['post_id'] = []\n",
    "summary_50htz['pre_cre'] = []\n",
    "summary_50htz['post_cre'] = []\n",
    "summary_50htz['std'] = []\n",
    "summary_50htz['var'] =[]\n",
    "for ii in range(len(data['uid'])):\n",
    "    sample=range(0,len(data['amps'][ii]))\n",
    "\n",
    "    # plot whole experiment\n",
    "    if show_plot == True:\n",
    "        plt.figure(figsize=(15,3))\n",
    "        plt.plot(data['spike_times_relative_to_expt'][ii][sample], data['amps'][ii][sample], '.-', ms=20)\n",
    "        # for ii, (p,t,a) in enumerate(zip(pulse_ids[sample], spike_times_relative_to_expt[sample], amplitudes[sample]*1e3)):\n",
    "        #     plt.annotate(str(ii), xy=(t,a), textcoords='data')\n",
    "        plt.ylabel('Deconvolution Amp')\n",
    "        plt.xlabel('time (s)')\n",
    "        plt.title('Deconvolution Amplitude Of Entire Experiment (all freq), \\n%.3f, pre: %s %i, post: %s %i' %(data['uid'][ii], data['pre_cre'][ii], data['pre_id'][ii], data['post_cre'][ii], data['post_id'][ii]))\n",
    "\n",
    "    # create new dictionary for individual connections where trains are differentiated.\n",
    "    conn_dict={}\n",
    "    conn_dict['train_num'] = []\n",
    "    conn_dict['post_rec_id'] = []\n",
    "    conn_dict['amps'] = []\n",
    "    conn_dict['times_rel_to_expt'] = []\n",
    "    conn_dict['times_rel_to_train'] = []\n",
    "    conn_dict['pulse_num_within_train'] = [] \n",
    "    conn_dict['stim_freq'] = []\n",
    "    \n",
    "\n",
    "    start_train_index = 0\n",
    "    end_train_index = 0\n",
    "    train_num = 1\n",
    "    recording_id = data['post_syn_rec_id'][ii]\n",
    "    \n",
    "    # Walk though every pulse and group them acording to the recording id\n",
    "    for jj in range(1, len(recording_id)):\n",
    "        if (recording_id[jj-1] != recording_id[jj]):\n",
    "            end_train_index = jj-1  \n",
    "            #make the plot\n",
    "            sample = range(start_train_index, end_train_index+1) #+1 due to range\n",
    "            train_stim_freq=np.unique(data['stim_freq'][ii][sample])\n",
    "            rec_id=np.unique(data['post_syn_rec_id'][ii][sample])\n",
    "\n",
    "            # sanity checks\n",
    "            if (len(train_stim_freq) != 1) or (len(rec_id) != 1):\n",
    "                raise Exception('train should have one freq and one rec_id')\n",
    "            \n",
    "            # make data types more convenient\n",
    "            train_stim_freq = np.int64(train_stim_freq[0])\n",
    "            rec_id = rec_id[0]\n",
    "            \n",
    "            train_times_rel_to_expt = data['spike_times_relative_to_expt'][ii][sample]\n",
    "            train_times_rel_to_train = data['spike_times_relative_to_expt'][ii][sample]-data['spike_times_relative_to_expt'][ii][start_train_index]\n",
    "            train_amps = data['amps'][ii][sample]\n",
    "            pulse_num_within_train = data['pulse_num_within_train'][ii][sample]\n",
    "#            plt.plot(train_times_rel_to_train, train_amps, '.-', ms=20)\n",
    "            start_train_index = jj\n",
    "    \n",
    "            #TODO: remember to eliminate trains with missing pre synaptic spikes\n",
    "            if np.all(pulse_num_within_train[0:8] == np.array([1,2,3,4,5,6,7,8])):\n",
    "                conn_dict['train_num'].append(train_num)\n",
    "                conn_dict['post_rec_id'].append(rec_id)\n",
    "                if data['pre_cre'][ii]=='pvalb':\n",
    "                    conn_dict['amps'].append(-train_amps[0:8]) #you could negate them here\n",
    "                else:\n",
    "                    conn_dict['amps'].append(train_amps[0:8]) #you could negate them here\n",
    "\n",
    "                conn_dict['times_rel_to_expt'].append(train_times_rel_to_expt[0:8])\n",
    "                conn_dict['times_rel_to_train'].append(train_times_rel_to_train[0:8])\n",
    "                conn_dict['pulse_num_within_train'].append(pulse_num_within_train[0:8])\n",
    "                conn_dict['stim_freq'].append(train_stim_freq)\n",
    "            \n",
    "            train_num += 1\n",
    "    df=pd.DataFrame(conn_dict)\n",
    "\n",
    "    # create 50 htz df\n",
    "    fifty=df[['times_rel_to_train', 'amps']][df['stim_freq']==50]\n",
    "    if len(fifty['amps'])<1:  # if there is not at least 1 train jump out of loop\n",
    "        print('No Fifty Htz trains: %.3f, pre: %i, post: %i' % \\\n",
    "              (data['uid'][ii], data['pre_id'][ii], data['post_id'][ii]))\n",
    "        continue\n",
    "\n",
    "    # plot individual fifty hertz trains        \n",
    "    if show_plot == True:\n",
    "        plt.figure(figsize=(15,5))\n",
    "        for kk, row in fifty.iterrows():\n",
    "            # plot each train\n",
    "            plt.plot(range(1,9), row['amps'], '.-', ms=20)\n",
    "        plt.plot(range(1,9), fifty['amps'].mean(), '.-k', lw=5, ms=30)\n",
    "        plt.xlabel('Pulse #')\n",
    "        plt.ylabel('Deconvoled Amplitude')\n",
    "        plt.title('50 Hz Trains')\n",
    "    \n",
    "    # get amp stats for 50 htz trains\n",
    "    mean = fifty['amps'].mean()\n",
    "    var, std = var_std_of_amps_in_df(fifty)\n",
    "    \n",
    "    #remove_neg_coupled_data could be improved to handle multiple arrays so dont have to do hack below.\n",
    "    mean1, std1 = remove_neg_coupled_data(mean, std) \n",
    "    mean1, var1 = remove_neg_coupled_data(mean, var) \n",
    "    mean = mean1\n",
    "    std = std1\n",
    "    var = var1\n",
    "\n",
    "    cv = std/mean\n",
    "    \n",
    "    # populate summary dictionary\n",
    "    summary_50htz['cv'].append(cv)\n",
    "    summary_50htz['std'].append(std)\n",
    "    summary_50htz['mean'].append(mean)\n",
    "    summary_50htz['var'].append(var)\n",
    "    summary_50htz['uid'].append(data['uid'][ii])\n",
    "    summary_50htz['pre_id'].append(data['pre_id'][ii])\n",
    "    summary_50htz['post_id'].append(data['post_id'][ii])\n",
    "    summary_50htz['pre_cre'].append(data['pre_cre'][ii])\n",
    "    summary_50htz['post_cre'].append(data['post_cre'][ii])\n",
    "    \n",
    "    # plot coefficient of variation at each spike index for 50 Htz trains\n",
    "    if show_plot == True:\n",
    "        plt.figure(figsize=(15,5))\n",
    "        plt.plot(range(1,9), cv, ms=20)\n",
    "        plt.xlabel('Pulse #')\n",
    "        plt.ylabel(' CV of Deconvoled Amp')\n",
    "        plt.title('50 Hz Trains')\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    # plot amp mean and coefficient of variation for 50 htz trains\n",
    "    if show_plot == True:\n",
    "        plt.figure(figsize=(15,6))\n",
    "        plt.subplot(1,2,1)    \n",
    "        plt.plot(mean, cv, ms=20)\n",
    "        for mm, (a, c) in enumerate(zip(mean, cv)):\n",
    "            plt.annotate(str(mm+1), (a,c))\n",
    "        plt.xlabel('Mean deconvolved amplitude')\n",
    "        plt.ylabel('CV deconvolved amplitude')\n",
    "        plt.title('50 Htz trains')\n",
    "\n",
    "    \n",
    "    # first pulse histograms\n",
    "    if show_plot == True:\n",
    "        plt.subplot(1,2,2)    \n",
    "        fp=[]\n",
    "        for row in df['amps']:\n",
    "            fp.append(row[0])\n",
    "        plt.hist(fp)\n",
    "        plt.xlabel('Deconvolved amplitude')\n",
    "        plt.ylabel('Number')\n",
    "        plt.title('First Pulse (all frequencies)')\n",
    "    \n",
    "        plt.show()\n",
    "\n",
    "summary_df=pd.DataFrame(summary_50htz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df['mean'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make 1D long arrays for fitting by concatenating idividual trains (note that all pulses are included)\n",
    "\n",
    "# initiate data structures\n",
    "tlx3_to_sst = {'mean':{'list':[], 'array': []},\n",
    "               'var':{'list':[], 'array': []},\n",
    "               'cv2':{'list':[], 'array': []},\n",
    "               'cv_log':{'list':[], 'array': []}}\n",
    "\n",
    "pv_to_pv = {'mean':{'list':[], 'array': []},\n",
    "            'var':{'list':[], 'array': []},\n",
    "            'cv2':{'list':[], 'array': []},\n",
    "            'cv_log':{'list':[], 'array': []}}\n",
    "\n",
    "# Put dataframe in a list of arrays. Probably a better way to do this in pandas but not sure how\n",
    "for ii, row in summary_df.iterrows():\n",
    "    if row['pre_cre']=='tlx3':\n",
    "        tlx3_to_sst['mean']['list'].append(row['mean'])\n",
    "        tlx3_to_sst['cv2']['list'].append(row['cv']**2)\n",
    "        tlx3_to_sst['cv_log']['list'].append(np.log(row['cv']))\n",
    "        tlx3_to_sst['var']['list'].append(row['var'])\n",
    "\n",
    "    if row['pre_cre']=='pvalb':\n",
    "        pv_to_pv['mean']['list'].append(row['mean']) \n",
    "        pv_to_pv['cv2']['list'].append(row['cv']**2)\n",
    "        pv_to_pv['cv_log']['list'].append(np.log(row['cv']))\n",
    "        pv_to_pv['var']['list'].append(row['var'])\n",
    "\n",
    "# Do the transformation into 1d from 2d array for analysis on using all pulses\n",
    "tlx3_to_sst['mean']['array'] = np.concatenate(tlx3_to_sst['mean']['list'])\n",
    "tlx3_to_sst['cv2']['array'] = np.concatenate(tlx3_to_sst['cv2']['list'])\n",
    "tlx3_to_sst['cv_log']['array'] = np.concatenate(tlx3_to_sst['cv_log']['list'])\n",
    "tlx3_to_sst['var']['array'] = np.concatenate(tlx3_to_sst['var']['list'])\n",
    "\n",
    "\n",
    "pv_to_pv['mean']['array']  = np.concatenate(pv_to_pv['mean']['list'])\n",
    "pv_to_pv['cv2']['array'] = np.concatenate(pv_to_pv['cv2']['list'])\n",
    "pv_to_pv['cv_log']['array'] = np.concatenate(pv_to_pv['cv_log']['list'])\n",
    "pv_to_pv['var']['array'] = np.concatenate(pv_to_pv['var']['list'])\n",
    "\n",
    "\n",
    "# make some plots\n",
    "% matplotlib inline\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.plot(np.log(pv_to_pv['mean']['array']), np.log(pv_to_pv['cv2']['array']), '.b', ms=20, label='pv to pv')\n",
    "# plt.plot(np.log(tlx3_to_sst['mean']['array']), np.log(tlx3_to_sst['cv2']['array']), '.r', ms=20, label='tlx3 to sst')\n",
    "# plt.legend()\n",
    "\n",
    "a=plt.figure(figsize=(16, 6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(pv_to_pv['mean']['array'], pv_to_pv['var']['array'], '.b', ms=20, label='pv to pv')\n",
    "plt.plot(tlx3_to_sst['mean']['array'], tlx3_to_sst['var']['array'], '.r', ms=20, label='tlx3 to sst')\n",
    "plt.ylabel('variance of amplitude (deconvolved)')\n",
    "plt.xlabel('mean amplitute (deconvolved)')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(np.log(pv_to_pv['mean']['array']), np.log(pv_to_pv['var']['array']), '.b', ms=20, label='pv to pv')\n",
    "plt.plot(np.log(tlx3_to_sst['mean']['array']), np.log(tlx3_to_sst['var']['array']), '.r', ms=20, label='tlx3 to sst')\n",
    "plt.ylabel('log variance of amplitude (deconvolved)')\n",
    "plt.xlabel('log mean amplitute (deconvolved)')\n",
    "\n",
    "a.suptitle('Pulses 1:8 included (each point represents data for one pulse: i.e. each connection will have 8 points)', fontsize='16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Curve fitting with forced on non forced parameters to get to look at tradeoffs in p, n and q.\"\"\"\n",
    "\n",
    "# Different potential fits\n",
    "from scipy.optimize import curve_fit\n",
    "def fit_func(m, n, q):\n",
    "    return q/m - 1/n\n",
    "\n",
    "def f2(m, n, q):\n",
    "    return 0.5* np.log(q/m - 1/n)\n",
    "\n",
    "def var_mean_fit_n_q(m, n, q):\n",
    "    return q*m - (m**2/n)\n",
    "\n",
    "def var_mean_fit_n_q_linear(m, n, q):\n",
    "    return q - (m/n)\n",
    "    \n",
    "%matplotlib inline\n",
    "font={'size':22}\n",
    "matplotlib.rc('font', **font)  \n",
    "\n",
    "# #---------v vs m non linear space----------------\n",
    "# #unconstrained fit\n",
    "#\n",
    "# popt, pcov = curve_fit(var_mean_fit_n_q, tlx3_to_sst['mean']['array'], tlx3_to_sst['var']['array'])# , bounds=([1, 0], [10., np.inf] ))\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.plot(tlx3_to_sst['mean']['array'], tlx3_to_sst['var']['array'], '.b', ms = 10, label='data')   \n",
    "# plt.plot(tlx3_to_sst['mean']['array'], var_mean_fit_n_q(tlx3_to_sst['mean']['array'], *popt), 'g.', ms=10, label='unconstrained, fit: n=%f, q=%f' % tuple(popt))\n",
    "\n",
    "# #contstrain fit from n=1 to 10\n",
    "# colors=['r', 'k', 'y', 'c', 'm']\n",
    "# for ii, n in enumerate(range(1,6)):\n",
    "#     popt, pcov = curve_fit(var_mean_fit_n_q, tlx3_to_sst['mean']['array'], tlx3_to_sst['var']['array'],  bounds=([n-.000001, 0], [n+.000001, np.inf] ))\n",
    "#     plt.plot(tlx3_to_sst['mean']['array'], var_mean_fit_n_q(tlx3_to_sst['mean']['array'], *popt), '.', color=colors[ii],ms=10, label='fit: n=%.0f, q=%f' % tuple(popt))\n",
    "\n",
    "# plt.legend()\n",
    "# plt.xlabel('deconvolved amp mean')\n",
    "# plt.ylabel('deconvolved amp variance ')\n",
    "\n",
    "# # Do this again in linear space\n",
    "# plt.figure(figsize=(10, 10))\n",
    "\n",
    "#----------------------------------------------------------\n",
    "#------ these are full blown plots ------------------------\n",
    "#----------------------------------------------------------\n",
    "\n",
    "#----------tlx-----------------\n",
    "plt.figure(figsize=(15,12))\n",
    "x = tlx3_to_sst['mean']['array']\n",
    "y = tlx3_to_sst['var']['array']/tlx3_to_sst['mean']['array']\n",
    "\n",
    "#sort values for plotting\n",
    "arr1inds = x.argsort()\n",
    "x = x[arr1inds[::-1]]\n",
    "y = y[arr1inds[::-1]]\n",
    "\n",
    "#unconstrained fit\n",
    "popt, pcov = curve_fit(var_mean_fit_n_q_linear, x, y)# , bounds=([1, 0], [10., np.inf] ))\n",
    "p = x.mean()/(popt[0]*popt[1])\n",
    "plt.plot(x, y, '.b', ms = 14, label='data, tlx3 to sst')   \n",
    "plt.plot(x, var_mean_fit_n_q_linear(x, *popt), 'g', ms=10, lw=3,\n",
    "         label='unconstrained, fit: n=%f, q=%f, p=%f' % (popt[0], popt[1], p))\n",
    "\n",
    "#contstrain fit from n=1 to 10\n",
    "colors=['r', 'k', 'y', 'c', 'm']\n",
    "for ii, n in enumerate(range(1,6)):\n",
    "    popt, pcov = curve_fit(var_mean_fit_n_q_linear, x, y,  bounds=([n-.000001, 0], [n+.000001, np.inf] ))\n",
    "    p = x.mean()/(popt[0]*popt[1])\n",
    "    plt.plot(x, var_mean_fit_n_q_linear(x, *popt), lw=3, color=colors[ii],ms=10, \n",
    "             label=' fit: n=%.0f, q=%f, p=%f' % (popt[0], popt[1], p))\n",
    "\n",
    "    \n",
    "#----------pv-----------------\n",
    "y = pv_to_pv['var']['array']/pv_to_pv['mean']['array']\n",
    "x = pv_to_pv['mean']['array']\n",
    "#sort values for plotting\n",
    "arr1inds = x.argsort()\n",
    "x = x[arr1inds[::-1]]\n",
    "y = y[arr1inds[::-1]]\n",
    "\n",
    "popt, pcov = curve_fit(var_mean_fit_n_q_linear, x, y)# , bounds=([1, 0], [10., np.inf] ))\n",
    "p = x.mean()/(popt[0]*popt[1])\n",
    "plt.plot(x, y, '.r', ms = 14, label='data: pv to pv')   \n",
    "plt.plot(x, var_mean_fit_n_q_linear(x, *popt), 'g-', ms=10, lw=3,\n",
    "         label='unconstrained, fit: n=%f, q=%f, p=%f' % (popt[0], popt[1], p))\n",
    "\n",
    "#contstrain fit from n=1 to 10\n",
    "colors=['r', 'k', 'y', 'c', 'm']\n",
    "for ii, n in enumerate(range(2,20)):\n",
    "    popt, pcov = curve_fit(var_mean_fit_n_q_linear, x, y,  bounds=([n-.000001, 0], [n+.000001, np.inf]))\n",
    "    p = x.mean()/(popt[0]*popt[1])\n",
    "    plt.plot(x, var_mean_fit_n_q_linear(x, *popt), ms=10, lw=3,\n",
    "             label=' fit: n=%.0f, q=%f, p=%f' % (popt[0], popt[1], p))\n",
    "\n",
    "plt.ylim([0, .03])\n",
    "plt.legend(fontsize=16)\n",
    "plt.xlabel('deconvolved amp mean')\n",
    "plt.ylabel('deconvolved amp variance/mean ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------\n",
    "#------ summary plot for Tim's Columbia talk --------------\n",
    "#----------------------------------------------------------\n",
    "\n",
    "%matplotlib inline\n",
    "font={'size':22}\n",
    "matplotlib.rc('font', **font)  \n",
    "\n",
    "#----------tlx-----------------\n",
    "plt.figure(figsize=(15,12))\n",
    "x = tlx3_to_sst['mean']['array']\n",
    "y = tlx3_to_sst['var']['array']/tlx3_to_sst['mean']['array']\n",
    "\n",
    "#sort values for plotting\n",
    "arr1inds = x.argsort()\n",
    "x = x[arr1inds[::-1]]\n",
    "y = y[arr1inds[::-1]]\n",
    "\n",
    "#unconstrained fit\n",
    "popt, pcov = curve_fit(var_mean_fit_n_q_linear, x, y)# , bounds=([1, 0], [10., np.inf] ))\n",
    "p = x.mean()/(popt[0]*popt[1])\n",
    "plt.plot(x, y, '.b', ms = 20, label='tlx3 to sst')   \n",
    "plt.plot(x, var_mean_fit_n_q_linear(x, *popt), 'b', ms=10, lw=3)\n",
    "\n",
    "#contstrain fit from n=1 to 10\n",
    "colors=['r', 'k', 'y', 'c', 'm']\n",
    "for ii, n in enumerate(range(1,6)):\n",
    "    popt, pcov = curve_fit(var_mean_fit_n_q_linear, x, y,  bounds=([n-.000001, 0], [n+.000001, np.inf] ))\n",
    "    p = x.mean()/(popt[0]*popt[1])\n",
    "#     plt.plot(x, var_mean_fit_n_q_linear(x, *popt), lw=3, color=colors[ii],ms=10, \n",
    "#              label=' fit: n=%.0f, q=%f, p=%f' % (popt[0], popt[1], p))\n",
    "\n",
    "    \n",
    "#----------pv-----------------\n",
    "y = pv_to_pv['var']['array']/pv_to_pv['mean']['array']\n",
    "x = pv_to_pv['mean']['array']\n",
    "#sort values for plotting\n",
    "arr1inds = x.argsort()\n",
    "x = x[arr1inds[::-1]]\n",
    "y = y[arr1inds[::-1]]\n",
    "\n",
    "popt, pcov = curve_fit(var_mean_fit_n_q_linear, x, y)# , bounds=([1, 0], [10., np.inf] ))\n",
    "p = x.mean()/(popt[0]*popt[1])\n",
    "plt.plot(x, y, '.r', ms = 20, label='pv to pv')   \n",
    "plt.plot(x, var_mean_fit_n_q_linear(x, *popt), 'r-', ms=10, lw=3)\n",
    "\n",
    "#contstrain fit from n=1 to 10\n",
    "colors=['r', 'k', 'y', 'c', 'm']\n",
    "for ii, n in enumerate(range(1,20)):\n",
    "    popt, pcov = curve_fit(var_mean_fit_n_q_linear, x, y,  bounds=([n-.000001, 0], [n+.000001, np.inf]))\n",
    "    p = x.mean()/(popt[0]*popt[1])\n",
    "#     plt.plot(x, var_mean_fit_n_q_linear(x, *popt), ms=10, lw=3,\n",
    "#              label=' fit: n=%.0f, q=%f, p=%f' % (popt[0], popt[1], p))\n",
    "plt.ylim([0, .03])\n",
    "plt.legend()\n",
    "plt.xlabel('mean')\n",
    "plt.ylabel('variance/mean')\n",
    "plt.title('Amplitude of 50 Hz Trains')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
